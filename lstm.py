# -*- coding: utf-8 -*-
"""Bismillah ini yang terbaik.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xuQJKAbboHevyqxUD-04jQ6_DYObtENI
"""
import streamlit as st
import pandas as pd
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import plotly.graph_objects as go
import numpy as np
import tensorflow as tf

# Check if GPU is available
if tf.test.gpu_device_name():
    st.write('GPU found: {}'.format(tf.test.gpu_device_name()))
else:
    st.write("No GPU found, using CPU")

# Function to convert string values to bps
def convert_to_bps(value):
    if 'Mb/s' in value:
        return abs(float(value.replace(' Mb/s', '')) * 1e6)
    elif 'kb/s' in value:
        return abs(float(value.replace(' kb/s', '')) * 1e3)
    elif 'b/s' in value:
        return abs(float(value.replace(' b/s', '')))
    else:
        return 0.0

# Function to denormalize predictions
def denormalize(predictions, column_name, scaler, scaled_columns):
    predictions = predictions.flatten()
    min_val = scaler.data_min_[scaled_columns.index(column_name)]
    max_val = scaler.data_max_[scaled_columns.index(column_name)]
    denorm_predictions = predictions * (max_val - min_val) + min_val
    return denorm_predictions

# Function to build LSTM model
def build_lstm_model():
    model = Sequential([
        LSTM(80, activation='relu', input_shape=(1, 1), return_sequences=True),
        Dropout(0.2),
        LSTM(80, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Function to plot predictions using Plotly
def plot_predictions(title, actual, predicted, times, y_title, show_actual=True):
    fig = go.Figure()

    if show_actual:
        fig.add_trace(go.Scatter(x=times, y=[actual_val / 1e6 for actual_val in actual], mode='lines+markers', name='Actual', line=dict(color='blue')))
    fig.add_trace(go.Scatter(x=times, y=[pred_val / 1e6 for pred_val in predicted], mode='lines+markers', name='Predicted', line=dict(color='red')))

    fig.update_layout(title=title, xaxis_title='Jam', yaxis_title=y_title, legend_title='Legend')
    
    return fig


# Streamlit app
st.title("Sistem Prediksi dan Rekomendasi Bandwidth Malang Creative Center")

# CSV File Uploader
st.subheader("CSV File Uploader:")
uploaded_file = st.file_uploader("Upload CSV file:", type=['csv'])
if uploaded_file is not None:
    # Try different delimiters
    df = pd.read_csv(uploaded_file, sep=',', skiprows=1)
    
    # Strip any leading/trailing spaces from column names
    df.columns = df.columns.str.strip()
    
    # Check for unnamed columns and drop them
    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
    
    # st.write("Column names: ", df.columns.tolist())

    # Check if 'Time' is in columns
    if 'Time' not in df.columns:
        st.error("Column 'Time' not found in the CSV file. Please check the file format.")
        st.write(df.head())  # Display the first few rows for inspection
    else:
        # Adjust the date format to match the format in your CSV file
        df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')

    # Display initial data
    st.write(df)

    # Convert values to bps
    for col in df.columns[1:]:
        df[col] = df[col].apply(convert_to_bps)

    # Extract hour from Time column
    df['Hour'] = df['Time'].dt.hour

    # Create list of time options in HH:00 format
    time_options = [f'{str(hour).zfill(2)}:00' for hour in range(24)]

    # List of user input features
    user_input_features = [
        'ether1', 'sfp-sfpplus4 - modem', 'l2tp-out1', 'sfp1 - lantai 1', 'sfp2 - lantai 2', 
        'sfp3 - lantai 3', 'sfp4 - lantai 4', 'sfp5 - lantai 5', 'sfp-sfpplus1 - lantai 6', 
        'sfp-sfpplus2 - lantai 7', 'sfp-sfpplus3'
    ]

    # Select user input feature from user input list
    selected_feature = st.selectbox("Pilih Lantai :", user_input_features)
    input_f = f"In - {selected_feature}"
    output_f = f"Out - {selected_feature}"
    df['In_UserInput'] = df[input_f]
    df['Out_UserInput'] = df[output_f]
    df['Total_UserInput'] = df['In_UserInput'] + df['Out_UserInput']

    in_columns = [col for col in df.columns if col.startswith('In -') and input_f not in col]
    out_columns = [col for col in df.columns if col.startswith('Out -') and output_f not in col]
    df['In_Other'] = df[in_columns].sum(axis=1)
    df['Out_Other'] = df[out_columns].sum(axis=1)
    df['Total_Other'] = df['In_Other'] + df['Out_Other']

    # Create a combined column for hour and minute in HH:00 format
    df['Hour_Minute'] = df['Time'].dt.strftime('%H:00')

    # Select target hours based on user input
    target_hours_minutes = st.multiselect('Pilih Jam :', time_options)

    if st.button('Start Training') and target_hours_minutes:
        df_target = df[df['Hour_Minute'].isin(target_hours_minutes)]

        # Encode hour feature
        label_encoder = LabelEncoder()
        df_target['Hour_Minute_Encoded'] = label_encoder.fit_transform(df_target['Hour_Minute'])

        # Normalize the data
        scaled_columns = ['In_UserInput', 'Out_UserInput', 'In_Other', 'Out_Other']
        scaler = MinMaxScaler()
        df_target[scaled_columns] = scaler.fit_transform(df_target[scaled_columns])

        # Split data into features and targets
        X = df_target[['Hour_Minute_Encoded']]
        y_features = {
            'UserInput': ('In_UserInput', 'Out_UserInput'),
        }

        models = {}
        predictions = {}
        denorm_predictions = {}
        mae = {}
        mse = {}
        accuracy = {}

        total_epochs = 100  # total epochs for training
        progress_text = "Mesin sedang memprediksi, Mohon ditunggu..."
        progress_bar = st.progress(0, text=progress_text)  # initialize progress bar
        progress_step = 1 / (len(y_features) * 2 * total_epochs)  # step for each update

        for key, (y_in, y_out) in y_features.items():
            X_train_in, X_test_in, y_train_in, y_test_in = train_test_split(X, df_target[y_in], test_size=0.2, random_state=42)
            X_train_out, X_test_out, y_train_out, y_test_out = train_test_split(X, df_target[y_out], test_size=0.2, random_state=42)

            # Reshape features for LSTM input
            X_train_in = X_train_in.values.reshape((X_train_in.shape[0], 1, 1))
            X_test_in = X_test_in.values.reshape((X_test_in.shape[0], 1, 1))
            X_train_out = X_train_out.values.reshape((X_train_out.shape[0], 1, 1))
            X_test_out = X_test_out.values.reshape((X_test_out.shape[0], 1, 1))

            # Build and train models
            models[key] = {
                'in': build_lstm_model(),
                'out': build_lstm_model()
            }

            early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)

            # Training for 'in' model
            for epoch in range(total_epochs):
                models[key]['in'].fit(X_train_in, y_train_in, epochs=1, batch_size=1, verbose=0, callbacks=[early_stopping])
                progress_bar.progress((epoch + 1) * progress_step)

            # Training for 'out' model
            for epoch in range(total_epochs):
                models[key]['out'].fit(X_train_out, y_train_out, epochs=1, batch_size=1, verbose=0, callbacks=[early_stopping])
                progress_bar.progress((epoch + 1 + total_epochs) * progress_step)

            # Make predictions
            pred_in = models[key]['in'].predict(X_test_in)
            pred_out = models[key]['out'].predict(X_test_out)

            # Denormalize predictions
            denorm_pred_in = denormalize(pred_in, y_in, scaler, scaled_columns)
            denorm_pred_out = denormalize(pred_out, y_out, scaler, scaled_columns)

            predictions[key] = {
                'in': pred_in,
                'out': pred_out
            }

            denorm_predictions[key] = {
                'in': denorm_pred_in,
                'out': denorm_pred_out
            }

            # Denormalize actual values for plotting
            denorm_actual_in = denormalize(y_test_in.values, y_in, scaler, scaled_columns)
            denorm_actual_out = denormalize(y_test_out.values, y_out, scaler, scaled_columns)

            # Calculate MAE and MSE
            mae[key] = {
                'in': mean_absolute_error(denorm_actual_in, denorm_pred_in),
                'out': mean_absolute_error(denorm_actual_out, denorm_pred_out)
            }
            mse[key] = {
                'in': mean_squared_error(denorm_actual_in, denorm_pred_in),
                'out': mean_squared_error(denorm_actual_out, denorm_pred_out)
            }

            # Calculate accuracy
            accuracy[key] = {
                'in': 100 - np.mean(np.abs((denorm_actual_in - denorm_pred_in) / denorm_actual_in)) * 100,
                'out': 100 - np.mean(np.abs((denorm_actual_out - denorm_pred_out) / denorm_actual_out)) * 100
            }

        # Display training complete message and balloons
        st.success('Proses Selesai!', icon="âœ…")
        st.balloons()

        # Display denormalized predictions
        st.subheader("ðŸš¨ Hasil Prediksi dan Rekomendasi ")
        times = target_hours_minutes
        times_str = [time for time in times]

        # Determine the dynamic label for predictions
        if 'lantai' in selected_feature.lower():
            label = selected_feature.split(" - ")[-1]
        else:
            label = 'user input'

        for key in y_features.keys():
            st.write(f"Prediksi untuk {label}:")
            for time, pred_in, pred_out in zip(times_str, denorm_predictions[key]['in'][:len(times)], denorm_predictions[key]['out'][:len(times)]):
                st.write(f'ðŸ”´ Rekomendasi Limitasi Bandwidth pada {time}:')
                st.write(f'ðŸ”¼ Upload Limit: {pred_in / 1e6:.2f} Mbps')
                st.write(f'ðŸ”½ Download Limit: {pred_out / 1e6:.2f} Mbps')

        # Determine the plot title
        plot_title_in = f'Prediksi In untuk {label}'
        plot_title_out = f'Prediksi Out untuk {label}'
        plot_title_total = f'Prediksi Total untuk {label}'

        # Plot predictions using Plotly
        for key, (y_in, y_out) in y_features.items():
            denorm_actual_in = denormalize(y_test_in.values, y_in, scaler, scaled_columns)
            denorm_actual_out = denormalize(y_test_out.values, y_out, scaler, scaled_columns)

            # Plot only predicted values for "in" traffic
            fig_in = plot_predictions(plot_title_in, denorm_actual_in[:len(times)], denorm_predictions[key]['in'][:len(times)], times_str, 'Kecepatan Internet In (Mbps)', show_actual=False)
            
            # Plot only predicted values for "out" traffic
            fig_out = plot_predictions(plot_title_out, denorm_actual_out[:len(times)], denorm_predictions[key]['out'][:len(times)], times_str, 'Kecepatan Internet Out (Mbps)', show_actual=False)
            
            actual_total = [a_in + a_out for a_in, a_out in zip(denorm_actual_in[:len(times)], denorm_actual_out[:len(times)])]
            pred_total = [p_in + p_out for p_in, p_out in zip(denorm_predictions[key]['in'][:len(times)], denorm_predictions[key]['out'][:len(times)])]
            
            # Plot actual vs predicted values for "total" traffic
            fig_total = plot_predictions(plot_title_total, actual_total, pred_total, times_str, 'Kecepatan Internet Total (Mbps)', show_actual=True)

            st.plotly_chart(fig_in)
            st.plotly_chart(fig_out)
            st.plotly_chart(fig_total)

        # Print all MAE, MSE values and Accuracy
        # st.write("Metrics:")
        # for key in y_features.keys():
        #     st.write(f"{label} In:")
        #     st.write(f"  MAE: {mae[key]['in']:.2f}")
        #     st.write(f"  MSE: {mse[key]['in']:.2f}")
        #     st.write(f"  Accuracy: {accuracy[key]['in']:.2f}%")
        #     st.write(f"{label} Out:")
        #     st.write(f"  MAE: {mae[key]['out']:.2f}")
        #     st.write(f"  MSE: {mse[key]['out']:.2f}")
        #     st.write(f"  Accuracy: {accuracy[key]['out']:.2f}%")
